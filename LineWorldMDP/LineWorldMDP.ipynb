{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LineWorldMDP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp2CJZ0D0uWC"
      },
      "source": [
        "# LineWorld MDP\r\n",
        "\r\n",
        "This notebook provides a proof of concept of behavior initialization. Agents are simulated in the 1D LineWorld from [Kumar et. al.](https://bair.berkeley.edu/blog/2019/12/05/bear/) and demonstrate the neccessity for data collection. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA-trFia1kv5"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRbyUpfN91FF",
        "outputId": "fb66b449-20cf-4937-b3c8-8bd1fa34e740"
      },
      "source": [
        "import numpy as np\r\n",
        "import torch\r\n",
        "import random\r\n",
        "import math\r\n",
        "import time\r\n",
        "import torch.nn as nn\r\n",
        "from collections import deque\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "torch.manual_seed(2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb16dd7bb58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d35PMK4K1m4N"
      },
      "source": [
        "### The 1D Line World MDP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2AYH2WQ-GQB"
      },
      "source": [
        "class LineWorldMDP:\r\n",
        "    def __init__(self, num_states):\r\n",
        "        # initialize MDP\r\n",
        "        self.end           = False\r\n",
        "        self.current_state = 1\r\n",
        "        self.num_actions   = 2\r\n",
        "        self.num_states    = num_states\r\n",
        "        self.step_count = 0\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        # reset MDP\r\n",
        "        self.step_count = 0\r\n",
        "        self.end = False\r\n",
        "        self.current_state = 1\r\n",
        "        state = np.zeros(self.num_states)\r\n",
        "        state[self.current_state - 1] = 1.\r\n",
        "        return state\r\n",
        "\r\n",
        "    def step(self, action):\r\n",
        "        # increment step count\r\n",
        "        self.step_count += 1\r\n",
        "\r\n",
        "        # positive reward for right action\r\n",
        "        if action == 1:\r\n",
        "            self.current_state += 1\r\n",
        "            reward = 1\r\n",
        "        # negative reward for left action\r\n",
        "        else:\r\n",
        "            self.current_state -= 1\r\n",
        "            reward = -1\r\n",
        "            self.end = True\r\n",
        "\r\n",
        "        # check step counter\r\n",
        "        if self.step_count >= 1000 or self.current_state==self.num_states:\r\n",
        "            self.end = True\r\n",
        "\r\n",
        "        state = np.zeros(self.num_states)\r\n",
        "        state[self.current_state - 1] = 1\r\n",
        "        return state, reward, self.end, {}\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7E-I7HA1xfE"
      },
      "source": [
        "### Neural Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivc4vVp_-HLV"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "    def __init__(self, num_inputs, num_actions):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.num_actions = num_actions\r\n",
        "        self.l1 = nn.Linear(num_inputs, 32)\r\n",
        "        self.relu2 = nn.ReLU()\r\n",
        "        self.l3 = nn.Linear(32, num_actions)\r\n",
        "\r\n",
        "    def forward(self, states):\r\n",
        "        x = to_torch(states)\r\n",
        "        x = to_torch(x)\r\n",
        "        x = self.l1(x)\r\n",
        "        x = self.relu2(x)\r\n",
        "        x = self.l3(x)\r\n",
        "        return x\r\n",
        "    \r\n",
        "    def get_actions(self, steps, states):\r\n",
        "        if random.random() > 0.001 + (0.4 - 0.001) * math.exp(-1. * steps / 200):\r\n",
        "            x = to_torch(states)\r\n",
        "            x = self.forward(x)\r\n",
        "            x = torch.argmax(x).type(torch.int64)\r\n",
        "            return x\r\n",
        "        else:\r\n",
        "            return to_torch(np.random.randint(low=0, high=self.num_actions)).type(torch.int64)\r\n",
        "\r\n",
        "\r\n",
        "def to_torch(x, **kwargs):\r\n",
        "\tif torch.is_tensor(x):\r\n",
        "\t\treturn x.to(DEVICE)\r\n",
        "\telse:\r\n",
        "\t\treturn torch.tensor(x, device=DEVICE, dtype=torch.float32, **kwargs)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajBrBi9W11HI"
      },
      "source": [
        "### Replay Buffer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCyycb1a-NqD"
      },
      "source": [
        "class ReplayBuffer():\r\n",
        "    def __init__(self, capacity):\r\n",
        "        self.buffer = deque(maxlen=capacity)\r\n",
        "    \r\n",
        "    def push(self, state, action, reward, next_state, done):\r\n",
        "        state      = np.expand_dims(state, 0)\r\n",
        "        next_state = np.expand_dims(next_state, 0)\r\n",
        "            \r\n",
        "        self.buffer.append((state, action, reward, next_state, done))\r\n",
        "    \r\n",
        "    def empty(self):\r\n",
        "        while self.buffer:\r\n",
        "          _ = self.buffer.pop()\r\n",
        "\r\n",
        "    def sample(self, batch_size):\r\n",
        "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\r\n",
        "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.buffer)\r\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8jhLy4t14tq"
      },
      "source": [
        "### Train using Q-Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c9xT2S9-Afq"
      },
      "source": [
        "def train(replay_buffer):\r\n",
        "    states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\r\n",
        "    states = to_torch(states)\r\n",
        "    actions = to_torch(actions).type(torch.int64)\r\n",
        "    rewards = to_torch(rewards)\r\n",
        "    next_states = to_torch(next_states)\r\n",
        "    dones = to_torch(dones)\r\n",
        "    vals = model(states)\r\n",
        "    vals = vals.gather(1, actions.unsqueeze(1))\r\n",
        "    next_vals = model(next_states).max(1)[0]\r\n",
        "    target = rewards + gamma*next_vals*(1 - dones)\r\n",
        "    td_error = (target.detach() - vals).pow(2).mean()\r\n",
        "    optimizer.zero_grad()\r\n",
        "    td_error.backward()\r\n",
        "    optimizer.step()\r\n",
        "    return td_error.item()    \r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ijA-xQl1_iA"
      },
      "source": [
        "### Simulate Agent in Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWZys5gL-fpU"
      },
      "source": [
        "def main(env, model, replay_buffer, data_collect):\r\n",
        "    log_dict = {}\r\n",
        "    log_dict['rewards'] = []\r\n",
        "    log_dict['average_rewards'] = []\r\n",
        "    log_dict['average_error'] = []\r\n",
        "    log_dict['td_error'] = []\r\n",
        "    log_dict['ep_count'] = []\r\n",
        "    state = env.reset()\r\n",
        "    loss = torch.FloatTensor([0])\r\n",
        "    steps = 0\r\n",
        "    ep_step_count = 0\r\n",
        "    ep_reward = 0\r\n",
        "    ep_loss = 0\r\n",
        "    while steps < num_steps:\r\n",
        "        action = model.get_actions(steps, state)\r\n",
        "        next_state, reward, done, _ = env.step(action)\r\n",
        "        ep_reward += reward\r\n",
        "        steps += 1\r\n",
        "        ep_step_count += 1\r\n",
        "\r\n",
        "        if len(replay_buffer) > batch_size:\r\n",
        "            loss = train(replay_buffer)\r\n",
        "        ep_loss += loss\r\n",
        "\r\n",
        "        if steps%data_collect==0:\r\n",
        "            replay_buffer.push(state, action, reward, next_state, done)\r\n",
        "        state = next_state\r\n",
        "\r\n",
        "        if done:\r\n",
        "            state = env.reset()\r\n",
        "            ep_step_count = 0\r\n",
        "            done = False\r\n",
        "            log_dict['rewards'].append(ep_reward)\r\n",
        "            log_dict['td_error'].append(ep_loss)\r\n",
        "            if len(log_dict['rewards']) > window_size:\r\n",
        "                log_dict['average_rewards'].append(np.mean(log_dict['rewards'][-window_size:]))\r\n",
        "                log_dict['average_error'].append(np.mean(log_dict['td_error'][-window_size:]))\r\n",
        "            log_dict['ep_count'].append(steps)\r\n",
        "            ep_loss = 0\r\n",
        "            ep_reward = 0\r\n",
        "        \r\n",
        "        if steps % log_interval==0:\r\n",
        "            print('\\tSteps: ', steps,'/', num_steps,'\\tReward:', \r\n",
        "                log_dict['rewards'][-1],'\\tMax Reward:',max(log_dict['rewards']),'\\tTD Error:',log_dict['td_error'][-1],'\\tTime:', time.time() - start_time)\r\n",
        "\r\n",
        "    return log_dict    \r\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPs6FbZi2D97"
      },
      "source": [
        "## Plotting utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AObOf8h0-iSI"
      },
      "source": [
        "def res_plot(log_dir, log_dir_off):\r\n",
        "\t# plot rewards\r\n",
        "    fig = plt.figure()\r\n",
        "    plt.title('Average Returns', fontsize=24)\r\n",
        "    plt.plot(log_dir['average_rewards'][-200:])\r\n",
        "    plt.plot(log_dir_off['average_rewards'][-200:])\r\n",
        "    plt.xlabel('Steps', fontsize=18)\r\n",
        "    plt.ylabel('Returns', fontsize=18)\r\n",
        "    plt.legend(['No Dataset','Sub-Optimal Dataset'])\r\n",
        "    plt.show()\r\n",
        "    fig.savefig('plot_rewards.png', dpi=600, bbox_inches='tight')\r\n",
        "\r\n",
        "def plot_regret(log):\r\n",
        "\t# plot rewards\r\n",
        "    fig = plt.figure()\r\n",
        "    plt.title('Regret', fontsize=24)\r\n",
        "    for j in regret_states:\r\n",
        "        plt.plot(j - max(log[j]))\r\n",
        "    plt.xlabel('States', fontsize=18)\r\n",
        "    plt.ylabel('Regret', fontsize=18)\r\n",
        "    plt.legend(regret_states)\r\n",
        "    plt.show()\r\n",
        "    fig.savefig('plot_regret.png', dpi=600, bbox_inches='tight')\r\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmBrhD613Bc4"
      },
      "source": [
        "## Experiment-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMVZWd3R2J_r"
      },
      "source": [
        "### Train Agent without a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P7Z11Mb-i_P",
        "outputId": "06d2dff8-199d-4d59-aaf0-ddec9fc82643"
      },
      "source": [
        "# hyperparameters\r\n",
        "lr = 0.001\r\n",
        "gamma = 0.95\r\n",
        "batch_size = 32\r\n",
        "num_states = 200\r\n",
        "num_steps = 20000\r\n",
        "window_size = 20\r\n",
        "log_interval = 1000\r\n",
        "buffer_size = 1000\r\n",
        "start_time = time.time()\r\n",
        "\r\n",
        "# initialize env and agent\r\n",
        "env = LineWorldMDP(num_states=num_states)\r\n",
        "model = Net(env.num_states, env.num_actions)\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\r\n",
        "replay_buffer = ReplayBuffer(buffer_size)\r\n",
        "\r\n",
        "# train agent without a dataset\r\n",
        "log_dict = main(env, model, replay_buffer, data_collect=20)\r\n",
        "replay_buffer.empty()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tSteps:  1000 / 20000 \tReward: 0 \tMax Reward: 2 \tTD Error: 0.4777216911315918 \tTime: 0.9100508689880371\n",
            "\tSteps:  2000 / 20000 \tReward: 11 \tMax Reward: 11 \tTD Error: 11.677760362625122 \tTime: 2.620239734649658\n",
            "\tSteps:  3000 / 20000 \tReward: 0 \tMax Reward: 15 \tTD Error: 2.786705732345581 \tTime: 4.370684862136841\n",
            "\tSteps:  4000 / 20000 \tReward: 11 \tMax Reward: 15 \tTD Error: 22.477051496505737 \tTime: 6.112466096878052\n",
            "\tSteps:  5000 / 20000 \tReward: 11 \tMax Reward: 15 \tTD Error: 29.97073209285736 \tTime: 7.794602632522583\n",
            "\tSteps:  6000 / 20000 \tReward: 11 \tMax Reward: 15 \tTD Error: 33.50468623638153 \tTime: 9.49263596534729\n",
            "\tSteps:  7000 / 20000 \tReward: 11 \tMax Reward: 15 \tTD Error: 33.52526938915253 \tTime: 11.23152232170105\n",
            "\tSteps:  8000 / 20000 \tReward: 11 \tMax Reward: 15 \tTD Error: 38.18375647068024 \tTime: 12.9408540725708\n",
            "\tSteps:  9000 / 20000 \tReward: 11 \tMax Reward: 15 \tTD Error: 38.32193636894226 \tTime: 14.671411275863647\n",
            "\tSteps:  10000 / 20000 \tReward: 11 \tMax Reward: 15 \tTD Error: 45.23063349723816 \tTime: 16.422346830368042\n",
            "\tSteps:  11000 / 20000 \tReward: 199 \tMax Reward: 199 \tTD Error: 664.8954741954803 \tTime: 18.14125680923462\n",
            "\tSteps:  12000 / 20000 \tReward: 199 \tMax Reward: 199 \tTD Error: 743.6706718206406 \tTime: 19.928791999816895\n",
            "\tSteps:  13000 / 20000 \tReward: 199 \tMax Reward: 199 \tTD Error: 804.5788292884827 \tTime: 21.61044454574585\n",
            "\tSteps:  14000 / 20000 \tReward: 199 \tMax Reward: 199 \tTD Error: 817.3548753261566 \tTime: 23.38617753982544\n",
            "\tSteps:  15000 / 20000 \tReward: 199 \tMax Reward: 199 \tTD Error: 852.460430264473 \tTime: 25.122944116592407\n",
            "\tSteps:  16000 / 20000 \tReward: 199 \tMax Reward: 199 \tTD Error: 913.2797122001648 \tTime: 26.848987579345703\n",
            "\tSteps:  17000 / 20000 \tReward: 199 \tMax Reward: 199 \tTD Error: 923.9582773447037 \tTime: 28.560177087783813\n",
            "\tSteps:  18000 / 20000 \tReward: 33 \tMax Reward: 199 \tTD Error: 182.85331392288208 \tTime: 30.298699140548706\n",
            "\tSteps:  19000 / 20000 \tReward: 199 \tMax Reward: 199 \tTD Error: 939.7250473499298 \tTime: 32.03096342086792\n",
            "\tSteps:  20000 / 20000 \tReward: 199 \tMax Reward: 199 \tTD Error: 1051.1263530552387 \tTime: 33.73273491859436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqj2LDia2ZDc"
      },
      "source": [
        "### Train agent with a sub-optimal dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EVIjGwDEu9m",
        "outputId": "700d8616-d8dc-43f7-93cc-dcceea7c8dd4"
      },
      "source": [
        "# construct dataset of sub-optimal actions\r\n",
        "off_replay_buffer = ReplayBuffer(buffer_size)\r\n",
        "\r\n",
        "state = env.reset()\r\n",
        "for _ in range(20*batch_size):\r\n",
        "  action = 0\r\n",
        "  next_state, reward, done, _ = env.step(action)\r\n",
        "  off_replay_buffer.push(state, action, reward, next_state, done)\r\n",
        "  if done:\r\n",
        "    state = env.reset()\r\n",
        "    ep_step_count = 0\r\n",
        "    done = False\r\n",
        "\r\n",
        "# initialize model and env\r\n",
        "off_model = Net(env.num_states, env.num_actions)\r\n",
        "optimizer = torch.optim.Adam(off_model.parameters(), lr=lr)\r\n",
        "\r\n",
        "# train agent\r\n",
        "log_dict_off = main(env, off_model, off_replay_buffer, data_collect=20)\r\n",
        "replay_buffer.empty()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tSteps:  1000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 123.82677173614502\n",
            "\tSteps:  2000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.601226806640625 \tTime: 125.1894781589508\n",
            "\tSteps:  3000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 126.55703616142273\n",
            "\tSteps:  4000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.601226806640625 \tTime: 127.90469622612\n",
            "\tSteps:  5000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 129.27998995780945\n",
            "\tSteps:  6000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 42.323604583740234 \tTime: 130.62262082099915\n",
            "\tSteps:  7000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 131.95052576065063\n",
            "\tSteps:  8000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 133.27531123161316\n",
            "\tSteps:  9000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 134.6241397857666\n",
            "\tSteps:  10000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 135.96176552772522\n",
            "\tSteps:  11000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 137.33615803718567\n",
            "\tSteps:  12000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 138.6804826259613\n",
            "\tSteps:  13000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 140.02875113487244\n",
            "\tSteps:  14000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.601226806640625 \tTime: 141.3518807888031\n",
            "\tSteps:  15000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.622005462646484 \tTime: 142.6838355064392\n",
            "\tSteps:  16000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 144.013090133667\n",
            "\tSteps:  17000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 145.35522651672363\n",
            "\tSteps:  18000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 146.7257342338562\n",
            "\tSteps:  19000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 148.07639932632446\n",
            "\tSteps:  20000 / 20000 \tReward: -1 \tMax Reward: 1 \tTD Error: 43.618141174316406 \tTime: 149.4211061000824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw2vvf-a2zQR"
      },
      "source": [
        "### Generate Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "KrkQOQjcHw-6",
        "outputId": "4a596b12-70ce-4c68-8435-75daa3a0383e"
      },
      "source": [
        "res_plot(log_dict, log_dict_off)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOIsGAAk3FxT"
      },
      "source": [
        "## Experiment-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc9sWdAsISU6"
      },
      "source": [
        "lr = 0.001\r\n",
        "gamma = 0.99\r\n",
        "batch_size = 32\r\n",
        "num_steps = 5000\r\n",
        "window_size = 20\r\n",
        "log_interval = 1000\r\n",
        "buffer_size = 1000\r\n",
        "start_time = time.time()\r\n",
        "\r\n",
        "log = {}\r\n",
        "for num_states in [10,50,100,200,500,1000]:\r\n",
        "    print('Number of States:', num_states, '\\n')\r\n",
        "    env = LineWorldMDP(num_states=num_states)\r\n",
        "    model = Net(env.num_states, env.num_actions)\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\r\n",
        "    replay_buffer = ReplayBuffer(buffer_size)\r\n",
        "    \r\n",
        "    for _ in range(2*batch_size):\r\n",
        "      action = 0\r\n",
        "      next_state, reward, done, _ = env.step(action)\r\n",
        "      replay_buffer.push(state, action, reward, next_state, done)\r\n",
        "      if done:\r\n",
        "        state = env.reset()\r\n",
        "        ep_step_count = 0\r\n",
        "        done = False\r\n",
        "\r\n",
        "    log_dict = main(env, model, replay_buffer, data_collect=10)\r\n",
        "    log[num_states] = log_dict['average_rewards']\r\n",
        "    replay_buffer.empty()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}