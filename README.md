## Imitation-learning-project

## Tasks for this week
- [ ] Read 2 papers of your choice
- [ ] Go through the code base
- [ ] Apply code on 1 small task (without needing GPU)
- [ ] Meet with prof

## General Outline
The project aims to solve/build a single research idea by balancing its theory with empirical evaluation. We hope to begin by gaining intuition about the problem and addressing it on a simple toy task. The method can then be extended to non-trivial robot control tasks in order to compare its efficacy with baseline algorithms. 


<!-- ### Multi-Agent Path Finding
* [Lifelong Multi-Agent Path Finding in A Dynamic Environment](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8581181)
* [PRIMAL: Pathfinding via Reinforcement and Imitation Multi-Agent Learning](https://arxiv.org/pdf/1809.03531.pdf)
* [PRIMAL2: Pathfinding via Reinforcement and Imitation Multi-Agent Learning - Lifelong](https://arxiv.org/pdf/2010.08184.pdf)
* [Graph Neural Networks for Decentralized Multi-Robot Path Planning](https://arxiv.org/pdf/1912.06095.pdf)

### Other Similar problems/ GNN Approaches 
* [Learning Attentional Communication for Multi-Agent Cooperation](https://arxiv.org/pdf/1805.07733.pdf)
* [Multi-Agent Routing Value Iteration Network](https://arxiv.org/pdf/2007.05096.pdf) -->

## Paper List
I guess we can pick 2 papers to read by entering our name in the `Name` column. The list consists of basic papers which will help you get started on RL. In case you have any other papers you are interested in then feel free to put it here. Tasks include the following-
* Read papers completely
* Study the code base
* Run code on a smaller problem (potentially MDP)

|Paper|Code Link|Name|Implementation Task|
|:---:|:-------:|:--:|:-----------------:|
|[SAC](https://arxiv.org/pdf/1801.01290.pdf)|[here](https://github.com/denisyarats/pytorch_sac)|-|-|
|[DDPG](https://arxiv.org/pdf/1509.02971.pdf)|[here](https://github.com/sfujim/TD3)|-|-|
|[TD3](https://arxiv.org/pdf/1802.09477.pdf)|[here](https://github.com/sfujim/TD3)|-|-|
|[PPO](https://arxiv.org/pdf/1707.06347.pdf)|[here](https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail)|-|-|
|[Learning by Cheating](https://arxiv.org/pdf/1912.12294.pdf)|[here](https://github.com/dotchen/LearningByCheating)|Reza|-|
|[Eligibility Traces](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf)|[here](https://github.com/ShangtongZhang/reinforcement-learning-an-introduction)|Karush|-|
|[Dyna Planning](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf)|[here](https://github.com/ShangtongZhang/reinforcement-learning-an-introduction)|Reza|-|
|[A3C](https://arxiv.org/pdf/1602.01783.pdf)|[here](https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail)|-|-|

A longer list of papers is available [here](https://csc2541-f18.github.io/).

## Distribution of Tasks
As discussed, we can all pick one algorithm to implement and improve on a small task. In case our improvements work, we will apply these on new tasks and finalise results. Upon completion we will package our code base and distribute duties for report and presentation.

|Task|Karush|Reza|Mohammad|
|:--:|:----:|:--:|:------:|
|Implement Algo-1 on small task|:heavy_check_mark:|-|-|
|Implement Algo-2 on small task|-|:heavy_check_mark:|-|
|Implement Algo-3 on small task|-|-|:heavy_check_mark:|
|Improve Algo-1 on small task|:heavy_check_mark:|-|-|
|Improve Algo-2 on small task|-|:heavy_check_mark:|-|
|Improve Algo-3 on small task|-|-|:heavy_check_mark:|
|Apply Algo-1 on new tasks|:heavy_check_mark:|-|-|
|Apply Algo-2 on new tasks|-|:heavy_check_mark:|-|
|Apply Algo-3 on new tasks|-|-|:heavy_check_mark:|
|Package code base|:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|
|Write Report|:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|
|Wrap presentation|:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|

## Tentative Schedule

|Week|Task|Description|Completed|
|:--:|:--:|:---------:|:-------:|
|1|Literature Review|Brainstorm Ideas and jot down good ones|:heavy_check_mark:|
|2|Literature Review|Brainstorm Ideas, Meet with prof|need to meet with prof|
|3|Formulate Problem|Setup the problem with potential solutions| - |
|4|Implement Toy Problem|Solve base case and gain intuition| - |
|5|Implement Toy Problem|Complete base case solution and interpret results| - |
|6|Implement Algorithm|Solve main problem| - |
|7|Implement Algorithm|Solve main problem| - |
|9|Accumulate Results|Interpret and finalize results| - |
|10|Write Report|Draft and finalize report| - |
|11|Wrap Project|Package code base and wrap ppt| - |



